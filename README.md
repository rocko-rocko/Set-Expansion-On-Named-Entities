Set-Expansion-On-Named-Entities
===============================

Set expansion refers to expanding a given partial set of objects into a more complete set.  In set expansion, the user issues a query consisting of small number of seeds x1,x2,...xk  (assumption we will be given at-least three valid seeds) where each xi is a member of some  target set Si. The answer to query is a listing of other probable elements of Si.

Motivation 
==========

Existing:
* Google Sets.
Existing Usages:
* Google Sets has been used for a number of purposes in research community, including deriving features for named-entity recognition and evaluation of question answering systems.
* Existing shortcomings: Google Sets is a proprietary that may be changed any time. 

Basically set expansion is an amazing feature which links user to data which is beyond his focus(knowledge) and comes under his interest.  
• Practical utilities:  
With such a huge expansion of data/service providers, the most common requirement for a layman or technical person has shifted from single word query to a set based query where he wants information of all elements related to one entity class. For example: A person may want to know the names of all the presidents of a country but may be knowing only a 
few. He can expand this set to know many more such entities belonging to same set. Such a feature is not directly provided by Wikipedia.  
• Research Oriented usages/Other technologies dependent on it  
-> Set expansion tools are useful in creating comprehensive entity repository (for, say, brand names of each product category), in order to deliver better results to entity-oriented queries.   
-> The task of named entity recognition can also leverage the results generated by set expansion tools  

Approach
========
We divide our project into three main Phases:  
• Fetch the documents containing seed (phrase queries)  
• Rank them by any ranking method.  
• Use concept of semi-structured pages to extract candidate keys (i.e. pages contain seed and the candidate entities in same format as the seed occurs). This observation suggests that entities belonging to the same class (i.e. movies) will be linked by appearing in similar contexts (formatting structures) on the same page. A different Page may have 
different formatting structure.  
• Remove noisy candidate keys(relation similarity analysis) and rank the candidate keys to be the answer keys.  

Datasets
========
Wikipedia Corpus  

Index Generating Approach
=========================
1. Tokenized  
2. StopWord removal  
3. Stemming  
4. Lower case  
5. Diacritics normalization  
6. Per page extracted stringkeys in various sections(title, body, link, infobox, categories) keeping into account term frequency of each key.     

Each section is given different relevant weights.  
The whole idea is implemented by using various indexes:  
<b>Index1: (posting list + secondary index)</b>  
7. Applied MultiWay MergeSort over docs sorted on keys.  
8. Created final Posting list by using TF-IDF, with docId is ranked by weights  

KeyString1:DocId1:Weight1:DocId2:Weight2:....  
KeyString2:DocId1:Weight1:DocId2:Weight2:....  

<b>Index2: (per document)</b>  
7. Each docId has been mapped to all categories, infobox keys, text found in that doc.  

DocId1:c:categoryString1:categoryString2...  
DocId1:i:infoboxKey1:infoboxKey2...  
DocId1:t:textWord1:textWord2...   
The index is sorted on numeric DocID. 

<b>Index3: (classifier list + secondary index)</b>  
7. Mapping each keyString to all its respective docIds for category, infobox and text field.  

keyString:c:DocId1,DocId2....  
keyString:i:DocId1,DocId2....  
keyString:t:DocId1,DocId2....  

<b>Index4: (title id mapping + secondary index)</b>  
7. DocId:Title mapping for showing title as output in the end.  
DocId1:title1  
DocId2:titile2  

How to RUN
==========

1. Just download the src and bin folder
2. Create another folder named index along with above folders
3. This index folder will contain all the indexes that we have discussed above, but could not upload it here because of its large size in GB's
4. Run the source in eclipse (if you have the indexes :p)  

